{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import nbformat as nbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: streamlit in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (1.41.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (3.9.2)\n",
      "Requirement already satisfied: folium in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (0.19.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (1.5.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (5.10.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (5.29.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from folium) (0.8.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from folium) (2024.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=2.6->nbformat) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (308)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas streamlit seaborn matplotlib folium scikit-learn nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_handling(data_handling):\n",
    "    data_handling_list = []\n",
    "\n",
    "    # Read and append each file into a list\n",
    "    for data_handling_file in data_handling:\n",
    "        print(f\"Reading file: {data_handling_file}\")\n",
    "        df = pd.read_csv(data_handling_file)\n",
    "        print(f\"Shape of current file ({data_handling_file}): {df.shape}\")\n",
    "        data_handling_list.append(df)\n",
    "\n",
    "    # Combine all datasets into one DataFrame\n",
    "    print(\"\\nCombining all datasets into a single DataFrame...\")\n",
    "    data_handling_part_system = pd.concat(data_handling_list, ignore_index=True)\n",
    "    print(f\"Combined DataFrame shape: {data_handling_part_system.shape}\")\n",
    "\n",
    "    # Handle missing values\n",
    "    print(\"\\nHandling missing values with forward fill...\")\n",
    "    missing_before = data_handling_part_system.isnull().sum()\n",
    "    print(f\"Missing values before handling:\\n{missing_before}\")\n",
    "    data_handling_part_system.fillna(method='ffill', inplace=True)\n",
    "    missing_after = data_handling_part_system.isnull().sum()\n",
    "    print(f\"Missing values after handling:\\n{missing_after}\")\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    print(\"\\nRemoving duplicate entries...\")\n",
    "    duplicates_before = data_handling_part_system.duplicated().sum()\n",
    "    print(f\"Number of duplicates before removal: {duplicates_before}\")\n",
    "    data_handling_part_system.drop_duplicates(inplace=True)\n",
    "    duplicates_after = data_handling_part_system.duplicated().sum()\n",
    "    print(f\"Number of duplicates after removal: {duplicates_after}\")\n",
    "\n",
    "    # Feature engineering (e.g., create 'Month' from 'year')\n",
    "    if 'year' in data_handling_part_system.columns:\n",
    "        print(\"\\nFeature engineering: Extracting 'Month' from 'year' column...\")\n",
    "        print(f\"Converting 'year' column to datetime...\")\n",
    "        data_handling_part_system['year'] = pd.to_datetime(data_handling_part_system['year'], errors='coerce')\n",
    "        print(\"Dropping rows with invalid 'year' values...\")\n",
    "        data_handling_part_system.dropna(subset=['year'], inplace=True)\n",
    "        print(\"Creating 'Month' column from 'year' column...\")\n",
    "        data_handling_part_system['Month'] = data_handling_part_system['year'].dt.month\n",
    "        print(\"Sample of transformed data:\")\n",
    "        print(data_handling_part_system[['year', 'Month']].head())\n",
    "\n",
    "    return data_handling_part_system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 06:20:52.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.647 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:52.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define a function for data preprocessing\n",
    "def data_handling(data_file):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Feature engineering: Create 'Month' from 'year'\n",
    "    if 'year' in df.columns:\n",
    "        df['year'] = pd.to_datetime(df['year'], errors='coerce')\n",
    "        df['Month'] = df['year'].dt.month\n",
    "        df.dropna(subset=['year'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main function for Streamlit\n",
    "def main():\n",
    "    st.title(\"Air Quality Data Analysis System Using Streamlit\")\n",
    "    st.sidebar.title(\"Choose Options\")\n",
    "\n",
    "    # Upload CSV files\n",
    "    uploaded_files = st.sidebar.file_uploader(\"Upload CSV Files\", type=[\"csv\"], accept_multiple_files=True)\n",
    "    \n",
    "    if uploaded_files:\n",
    "        # Process uploaded files and combine them into one dataset\n",
    "        data = pd.concat([data_handling(file) for file in uploaded_files], ignore_index=True)\n",
    "        st.success(\"Datasets loaded and processed successfully!\")\n",
    "    else:\n",
    "        st.warning(\"Please upload at least one CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Sidebar options\n",
    "    show_data = st.sidebar.checkbox(\"Show Data\")\n",
    "    summary_stats = st.sidebar.checkbox(\"Exploratory Data Analysis (EDA)\")\n",
    "    model_building = st.sidebar.checkbox(\"Machine Learning Model Building\")\n",
    "    model_evaluation = st.sidebar.checkbox(\"Model Evaluation\")\n",
    "\n",
    "    # Show dataset details\n",
    "    if 'data' in locals():\n",
    "        st.subheader(\"Dataset Overview\")\n",
    "        rows, columns = data.shape\n",
    "        st.write(f\"The dataset contains **{rows} rows** and **{columns} columns**.\")\n",
    "        st.write(\"The columns in the dataset are:\", data.columns.tolist())\n",
    "\n",
    "        # Show data types and missing values\n",
    "        st.write(\"**Data Types:**\")\n",
    "        st.write(data.dtypes)\n",
    "        missing_values = data.isnull().sum()\n",
    "        st.write(\"**Missing Values:**\")\n",
    "        st.write(missing_values)\n",
    "\n",
    "        # Show raw data\n",
    "        if show_data:\n",
    "            st.subheader(\"Dataset Preview\")\n",
    "            st.dataframe(data.head())\n",
    "\n",
    "        # Summary statistics and visualizations\n",
    "        if summary_stats:\n",
    "            st.subheader(\"Summary Statistics\")\n",
    "            st.write(data.describe())\n",
    "\n",
    "            # Visualize numeric columns\n",
    "            numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "            st.subheader(\"Visualizations\")\n",
    "            for column in numeric_columns:\n",
    "                st.subheader(f\"Visualization for {column}\")\n",
    "                # Histogram\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.histplot(data[column], kde=True, bins=30, color='skyblue')\n",
    "                st.pyplot(plt)\n",
    "                # Box Plot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.boxplot(data[column], color='lightgreen')\n",
    "                st.pyplot(plt)\n",
    "\n",
    "        # Map for highest pollution levels\n",
    "        if 'latitude' in data.columns and 'longitude' in data.columns and 'PM2.5' in data.columns:\n",
    "            st.subheader(\"Map: Highest Pollution Levels\")\n",
    "            highest_pollution_station = data.loc[data['PM2.5'].idxmax()]\n",
    "            m = folium.Map(location=[highest_pollution_station['latitude'], highest_pollution_station['longitude']], zoom_start=10)\n",
    "            marker_cluster = MarkerCluster().add_to(m)\n",
    "            folium.Marker(\n",
    "                location=[highest_pollution_station['latitude'], highest_pollution_station['longitude']],\n",
    "                popup=f\"Station: {highest_pollution_station.get('Station', 'Unknown')}<br>PM2.5: {highest_pollution_station['PM2.5']}\",\n",
    "                icon=folium.Icon(color='red')\n",
    "            ).add_to(marker_cluster)\n",
    "            st.components.v1.html(m._repr_html_(), height=500)\n",
    "        else:\n",
    "            st.write(\"Map data (Latitude, Longitude, PM2.5) is incomplete in the dataset.\")\n",
    "\n",
    "        # Machine Learning Model Building\n",
    "        if model_building:\n",
    "            st.subheader(\"Machine Learning Model Building\")\n",
    "            target_column = st.selectbox(\"Select Target Variable:\", numeric_columns)\n",
    "            \n",
    "            if target_column:\n",
    "                # Feature and target separation\n",
    "                features = data.drop(columns=['year', 'Station', target_column], errors='ignore')\n",
    "                target = data[target_column]\n",
    "\n",
    "                # Handle missing values\n",
    "                features = pd.get_dummies(features, drop_first=True)  # Encode categorical features\n",
    "                imputer = SimpleImputer(strategy='mean')\n",
    "                features = imputer.fit_transform(features)\n",
    "\n",
    "                # Scale the features\n",
    "                scaler = StandardScaler()\n",
    "                features = scaler.fit_transform(features)\n",
    "\n",
    "                # Train-test split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Model selection\n",
    "                model_type = st.selectbox(\"Choose Model:\", [\"Linear Regression\", \"Random Forest\"])\n",
    "                if model_type == \"Linear Regression\":\n",
    "                    model = LinearRegression()\n",
    "                else:\n",
    "                    model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Model Evaluation\n",
    "                if model_evaluation:\n",
    "                    st.subheader(\"Model Evaluation\")\n",
    "                    st.write(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "                    st.write(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "                    st.write(\"R-Squared Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 06:20:30.732 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-17 06:20:30.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
